<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Omsee: User manual</TITLE>
</HEAD>
<BODY BGCOLOR="white">

<H1>Overview</H1>

<P>
This document provides an introduction to the native C++ Omsee API.
This API provides programmers with the ability to search through
(potentially very large) bodies of data using probabilistic methods.
</P>

<P>
<EM>Note:</EM>
The portion of the API currently documented here covers only the part
of Omsee concerned with searching through existing databases, not that
concerned with creating them.
</P>

<P>
It is probably a good idea to read the
<A HREF="intro_ir.html">Introduction to Information Retrieval</A> and the
<A HREF="intro.html">Introduction to Omsee</A> before reading this document,
or at least before attempting to use the API.  You may also wish to read
the <A HREF="quickstart.html">QuickStart</A> reference, for some simple
worked examples of Omsee usage.
</P>

<P>
This document does not detail the exact calling conventions (parameters
passed, return value, exceptions thrown, etc...) for each method in the API.
For such documentation, you should refer to the automatically extracted
documentation, which is generated from detailed comments in the source code,
and should thus remain up-to-date and accurate.  This documentation is
generated using the
<EM><A HREF="http://www.stack.nl/~dimitri/doxygen/index.html">Doxygen</A></EM>
application.  To save you having to generate this documentation yourself,
we include the <A HREF="apidoc/html/index.html">built version</A>
in our distributions, and also keep the
<A HREF="http://www.omsee.com/developer/docs/apidoc/html/index.html">latest version</A> on our website.
</P>

<H2>Errors and exceptions</H2>

<P>
Error reporting is often relegated to the back of manuals such as this.
However, it is extremely important to understand the errors which may be
caused by the operations which you are trying to perform.

This becomes particularly relevant when using a large system, with such
possibilities as databases which are being updated while you search
through them, and distributed enquiry systems.
</P>

<P>
Errors in Omsee are all reported by means of exceptions.  All exceptions
thrown by Omsee will be subclasses of
<A HREF="apidoc/html/class_OmError.html"><CODE>OmError</CODE></A>.  Note that
<CODE>OmError</CODE> is an abstract class; thus you must catch exceptions
by reference rather than by value.
</P>

<P>
There are two flavours of error, derived from <CODE>OmError</CODE>:
<UL><LI>
<A HREF="apidoc/html/class_OmLogicError.html"><CODE>OmLogicError</CODE></A>
- for error conditions due to programming errors, such as a misuse of the
API.  A finished application should not receive these errors (though it
would still be sensible to catch them).
</LI><LI>
<A HREF="apidoc/html/class_OmRuntimeError.html"><CODE>OmRuntimeError</CODE></A>
- for error conditions due to run time problems, such as failure to open
a database.  You must always be ready to cope with such errors.
</LI></UL>
</P>

<P>
Each of these flavours is further subdivided, such that any particular
error condition can be trapped by catching the appropriate exception.
If desired, a human readable explanation of the error can be retrieved
by calling
<A HREF="apidoc/html/class_OmError.html"><CODE>OmError::get_msg()</CODE></A>.
</P>

<P>
In addition, standard system errors may occur: these will be reported by
throwing appropriate exceptions.  Most notably, if the system runs out
of memory, a <CODE>std::bad_alloc()</CODE> exception will be thrown.
</P>

<H2>Terminology</H2>
<H3>Databases</H3>
<P>
These may also occasionally be called <EM>Indexes</EM>.  In Omsee (as
opposed to a database package) a database consists of little more than
indexed documents: this reflects the purpose of Omsee as an information
retrieval system, rather than an information storage system.
</P>
<P>
The exact contents of a database depend on the type (see
&quot;<A HREF="#database_types">Database Types</A>&quot; for more details
of the database types currently provided).
</P>

<H3>Queries</H3>
<P>
The information to be searched for is specified by a <EM>Query</EM>.  In
Omsee, queries are made up of a structured boolean tree, upon which
probabilistic weightings are imposed: when the search is performed, the
documents returned are filtered according to the boolean structure, and
weighted (and sorted) according to the probabilistic model of information
retrieval.
</P>

<H2>Memory handling</H2>
<P>
The user of Omsee does not usually need to worry about how Omsee performs
its memory allocation: Omsee objects can all be created and deleted as any
other C++ objects.  The convention is that whoever creates an object
is ultimately responsible for deleting it.  This becomes relevant when
passing a pointer to data to Omsee: Omsee will not assume that such
pointers remain valid across separate API calls, and it will be the
callers responsibility to delete the object pointed to, as and when
required.
</P>

<H2>The OmEnquire class</H2>

<P>
The <A HREF="apidoc/html/class_OmEnquire.html"><CODE>OmEnquire()</CODE></A> class
is central to all searching operations.  It provides an interface for
<UL><LI>
Specifying the database, or databases, to search across.
</LI><LI>
Specifying a query to perform.
</LI><LI>
Specifying a set of documents which a user considers relevant.
</LI><LI>
Given the supplied information, returning a ranked set of documents for
the user.
</LI><LI>
Given the supplied information, suggesting a ranked set of terms to add to the
query.
</LI><LI>
Returning information about the documents which matched, such as their
associated data, and which terms from the query were found within them.
</LI></UL>
</P>
<P>
A typical enquiry session will consist of most of these operations, in
various orders.  The OmEnquire class presents as few restrictions as
possible on the order in which operations should be performed.  Although
you must set the query before any operation which uses it, you can call
any of the other methods in any order.
</P>
<P>
Many operations performed by the OmEnquire class are performed lazily (ie,
just before their results are needed).  This need not concern the user
except to note that, as a result, errors may not be reported as soon as
would otherwise be expected.  In particular, errors regarding opening of
the database may be reported when a query is performed (although they
may not: you should catch exceptions in both situations).
</P>

<H2>Specifying a database</H2>

<P>
When creating an OmEnquire object, a database to search must be specified.
Databases are specified by creating an OmDatabase object and calling
<A HREF="apidoc/html/class_OmDatabase.html"><CODE>OmDatabase::add_database()</CODE></A>
.  This takes two parameters;
"<CODE><B>type</B></CODE>" which is a string
representing the type of the database to open, and
"<CODE><B>params</B></CODE>" which is a set of strings, the meaning of which
depend on the database type.
</P>
<P>
Note that these parameters <EM>are</EM> case sensitive.

<A NAME="database_types"><H3>Database types</H3></A>
The current types understood by Omsee are:
</P>
<TABLE>
<TR><TD VALIGN="top"><B>da_flimsy</B></TD><TD>
<P>
This is a proprietory, legacy format, holding a database in a
non-updatable form (ie, the database can't be altered, it is built
from an existing database).  We support read-only access to this,
and it is thus unlikely to be useful outside our company.
</P><P>
This takes one, two or three parameters.  If one parameter is supplied,
it represents the path to a directory containing the Record file in a file
called &quot;R&quot;, the Term file in a file called &quot;T&quot;, and
optionally the fast access key file in a file called &quot;keyfile&quot;
</P><P>
If two parameters are supplied, they represent the full paths to the
Record and Term file, respectively.  In this case, there is assumed to be
no keyfile.
</P><P>
If three parameters are supplied, the first two are the full paths to the
Record and Term files, respectively, and the third is the full path to
the keyfile.
</P>
</TD></TR>
<TR><TD VALIGN="top"><B>da_heavy</B></TD><TD>
This is a similar to da_flimsy, allowing access to the &quot;heavy duty&quot;
variant for larger documents.  This is the format produced by the
&quot;makeda&quot; utility, and is thus useful while new file formats have
not been created for the new development.
<BR>
It takes the same parameters as da_flimsy.
</TD></TR>
<TR><TD VALIGN="top"><B>db_flimsy</B></TD><TD>
<P>
This is a proprietory, legacy format, holding a database in a dynamically
updatable form (ie, the database can be altered while queries are being
performed on it.)  We support read-only access to this,
and it is thus unlikely to be useful outside our company.
</P><P>
This takes one or two parameters.  The first parameter is the full path to
the DB file.
</P><P>
If a second parameter is supplied, it represents the full path to the fast
access keyfile.  If a second parameter is not supplied, the keyfile will
be searched for at &lt;first_parameter&gt;_keyfile; if this doesn't exist,
no keyfile will be used.
</P><P>
It takes one parameter, which is the full path to the DB file.
</P>
</TD></TR>
<TR><TD VALIGN="top"><B>db_heavy</B></TD><TD>
This is a similar to db_flimsy, allowing access to the &quot;heavy duty&quot;
variant for larger documents.  We support read-only access to this,
and it is thus unlikely to be useful outside our company.
<BR>
It takes the same parameters as db_flimsy.
</TD></TR>
<TR><TD VALIGN="top"><B>inmemory</B></TD><TD>
This type is a database held entirely in memory.
It is really designed to be used as a cache while building databases
(ie, build up your records into one of these, and periodically
flush into the main database).
<BR>
However, for the moment a simple indexing routine is grafted
onto it, which indexes a file of text into records (roughly on a
paragraph by paragraph basis).
<BR>
It will eventually take no parameters at all, but for now takes an
arbitrary number of filenames: each one will be opened and indexed into the
database when the database is first used.
</TD></TR>
</TABLE>

<H3>Multiple databases</H3>

<P>
Omsee can search across several databases as easily as searching across a
single one.  Simply call
<A HREF="apidoc/html/class_OmDatabase.html"><CODE>OmDatabase::add_database()</CODE></A>
for each database that you wish to search through.
</P>
<P>
Other operations, such as setting the query, may be performed before or after
this call.  It is even possible to perform a query, add a further database,
and then perform the query again to get the results with the extra database
(although this isn't very likely to be useful in practice).
</P>

<H2>Specifying a query</H2>

<P>
Omsee implements both boolean and probabilistic searching.
There are two obvious ways in which a pure boolean query can be combined
with a pure probabilistic query:
<UL><LI>
First perform the boolean search to create a subset of the whole document
collection, and then do the probabilistic search on this subset, or
</LI><LI>
Do the probabilistic search, and then filter out the resulting documents
with a boolean query.
</LI></UL>
There is in fact a subtle difference in these two approaches. In the first,
the collection statistics for the probabilistic query will be
determined by the document subset which is obtained by running the boolean
query. In the second, the collection statistics for the probabilistic
query are determined by the whole document collection. These differences
can affect the final result.

</P>
<P>
Suppose for example the boolean query is
being used to retrieve documents in English in a database
containing English and French documents.
A word like
&quot;<EM>grand</EM>&quot;,
exists in both languages (with similar meanings), but is commoner in French
than English. In the English subset it could therefore be expected to have a higher
weight than it would get in the joint English and French
databases.

</P>
<P>
In fact Omsee, as described below, goes for the second approach, which
can be implemented very efficiently, despite the the fact that the first
is more exact.

</P>
<P>
In reality, Omsee performs the combined boolean and probabilistic searches
simultaneously.  This allows various optimisations to be performed, such
as giving up on calculating a boolean AND operation when the probabilistic
weights that could result from further documents can have no effect on the
result set.  These optimisations have been found to give a two- or
three-fold performance increase in certain cases.  The performance is
particularly good for queries containing many terms.
</P>

<H3>A query for a single term</H3>
<P>
All queries are represented by
<A HREF="apidoc/html/class_OmQuery.html"><CODE>OmQuery()</CODE></A>
objects.  The simplest possible (non-trivial) query is one which searches
for a single term.  This can be created as follows (where <CODE>tname</CODE> is the term to be searched for):
</P>
<PRE>
OmQuery query(tname);
</PRE>
<P>
A term in Omsee is represented simply by a string of binary characters.
Usually, when searching text, these characters will be the word which the
term represents, but during the information retrieval process Omsee
attaches no specific meaning to the term.
</P>
<P>
This constructor actually takes a couple of extra parameters, which may be
used to specify positional and frequency information for terms in the query:
<P>
<PRE>
OmQuery(const om_termname &amp; tname_,
        om_termcount wqf_ = 1,
        om_termpos term_pos_ = 0)
</PRE>
<P>
The <CODE>wqf</CODE> (<B>W</B>ithin <B>Q</B>uery <B>F</B>requency) is
a measure of how common a term is in the query.  This is particularly useful
when generating a query from an existing document, but may also be used
as a crude way of increasing the importance of a term in a query.  Note that,
if the intention is simply to ensure that a particular term is in the query
results, you should use a boolean AND rather than set a high wqf.
</P>
<P>
The <CODE>term_pos</CODE> represents the position of the term in the query.
This is used for phrase searching, passage retrieval, and other operations
which require knowledge of the order of terms in the query (such as returning
the set of matching terms in a given document in the same order as they
occur in the query).  If such operations are not required, the default
value of 0 may be used.
</P>
<P>
Note that it may not make much sense to specify a wqf other than 1 when
supplying a term position (unless you are trying to affect the weighting,
as previously described).
</P>
<P>
Note also that the results of <CODE>OmQuery(tname, 2)</CODE> and
<CODE>OmQuery(OM_MOP_OR, OmQuery(tname), OmQuery(tname))</CODE>
are exactly equivalent.
</P>




<H3>Compound queries</H3>
<P>
Out of single term queries, compound queries can be built up. A compound
is made up from two sub-queries with a connecting operator, where each
sub-query is a compound query or a single term query. This is done using
the following constructor:
</P>
<PRE>
OmQuery(om_queryop op_,
        const OmQuery &amp; left,
        const OmQuery &amp; right)
</PRE>
<P>
The two most commonly used operators are <CODE>OM_MOP_AND</CODE> and
<CODE>OM_MOP_OR</CODE>, which enable us to construct boolean queries made
up from the usual AND and OR operations. But in addition to this, a
probabilistic query in its simplest form, where we have a list of terms
which give rise to weights that need to be added together, is also made up
from a set of terms joined together with <CODE>OM_MOP_OR</CODE>.
</P>
<P>
The full set of available <CODE>om_queryop</CODE> operators is:
<TABLE>
<TR><TD VALIGN="top">
OM_MOP_AND
</TD><TD>
Return documents returned by both subqueries.
</TD></TR><TR><TD VALIGN="top">
OM_MOP_OR
</TD><TD>
Return documents returned by either subquery.
</TD></TR><TR><TD VALIGN="top">
OM_MOP_AND_NOT
</TD><TD>
Return documents returned by the left subquery but not the right subquery.
</TD></TR><TR><TD VALIGN="top">
OM_MOP_FILTER
</TD><TD>
As OM_MOP_AND, but use only weights from left subquery.
</TD></TR><TR><TD VALIGN="top">
OM_MOP_AND_MAYBE
</TD><TD>
Return documents returned by the left subquery, but adding
document weights from both subqueries.
</TD></TR><TR><TD VALIGN="top">
OM_MOP_XOR
</TD><TD>
Return documents returned by one subquery only.
</TD></TR>
</TABLE>
</P>


<H3>Understanding queries</H3>

<P>
Each term, t, in the query has a weight, w<sub>Q</sub>(t), given by

<PRE>
                     (K' + 1) f'<sub>t</sub>
             w<sub>Q</sub>(t) = ------------- w(t)
                      K'L' + f'<sub>t</sub>

</PRE>

where f'<sub>t</sub> is the wqf of t in the query, L' is the nql, or normalised query
length, and K' is a constant. And the weight w(t) is given by,


<PRE>
                   (r + h) (N - R - n + r + h)
        w(t) = log ---------------------------, where h = 1/2
                    (R - r + h) (n - r + h)
</PRE>

See the <A HREF="intro_ir.html">Introduction to Information Retrieval</A>
for a full discussion. For any particular document, D, if t indexes D, there
is a weight w<sub>D</sub>(t), which is the contribution, or partial score, of
term t to the total score for document D, and it is given by,

<PRE>
                     (K + 1) f<sub>t</sub>
             w<sub>D</sub>(t) = ---------- w<sub>Q</sub>(t)
                      KL + f<sub>t</sub>

</PRE>

</P>
<P>
A query can be thought of as a tree structure. At each node is
an <CODE>om_queryop</CODE> operator, and on the left and right branch are two other queries.
At each leaf node is a term, t, tranmitting documents and scores, D and
w<sub>D</sub>(t),
up the tree.
</P>
<P>
An OM_MOP_OR node transmits documents from both branches up the tree, summing the scores
when a document is found in both the left and right branch. For example,

<PRE>
                           docs       1    8    12    16    17    18
                           scores    7.3  4.1   3.2  7.6   3.8   4.7 ...
                             |
                             |
                         OM_MOP_OR
                         /       \
                        /         \
                       /           \
                      /             \
   docs     1   12   16   17         1   8   16   18
   scores  3.1 3.2  3.1  3.8 ...    4.2 4.1 4.5  4.7 ...
</PRE>

An OM_MOP_AND node transmits only the documents found on both branches up the tree,
again summing the scores,

<PRE>
                           docs       1   16
                           scores    7.3  7.6  ...
                             |
                             |
                         OM_MOP_AND
                         /       \
                        /         \
                       /           \
                      /             \
   docs     1   12   16   17         1   8   16   18
   scores  3.1 3.2  3.1  3.8 ...    4.2 4.1 4.5  4.7 ...
</PRE>

An OM_MOP_AND_NOT node transmits up the tree the documents on the left branch which are
not on the right branch. The scores are taken from the left branch. For example,
again summing the scores,

<PRE>
                           docs       12   17
                           scores    3.2  3.8 ...
                             |
                             |
                         OM_MOP_AND_NOT
                         /       \
                        /         \
                       /           \
                      /             \
   docs     1   12   16   17         1   8   16   18
   scores  3.1 3.2  3.1  3.8 ...    4.2 4.1 4.5  4.7 ...
</PRE>

An OM_MOP_MAYBE node transmits the documents up the tree from the left branch only,
but adds in the score from the right branch for documents which occur on both branches.
For example,

<PRE>
                           docs       1    12   16   17
                           scores    7.3  3.2  7.6  3.8 ...
                             |
                             |
                         OM_MOP_AND_MAYBE
                         /       \
                        /         \
                       /           \
                      /             \
   docs     1   12   16   17         1   8   16   18
   scores  3.1 3.2  3.1  3.8 ...    4.2 4.1 4.5  4.7 ...
</PRE>

OM_MOP_FILTER is like OM_MOP_AND, but weights are only transmitted from the left branch.
For example,

<PRE>
                           docs       1   16
                           scores    3.1  3.1  ...
                             |
                             |
                         OM_MOP_FILTER
                         /       \
                        /         \
                       /           \
                      /             \
   docs     1   12   16   17         1   8   16   18
   scores  3.1 3.2  3.1  3.8 ...    4.2 4.1 4.5  4.7 ...
</PRE>
OM_MOP_XOR is like OM_MOP_OR, but documents on both left and right branches are not
transmitted up the tree. For example,

<PRE>
                           docs       8    12    17    18
                           scores    4.1   3.2  3.8   4.7 ...
                             |
                             |
                         OM_MOP_XOR
                         /       \
                        /         \
                       /           \
                      /             \
   docs     1   12   16   17         1   8   16   18
   scores  3.1 3.2  3.1  3.8 ...    4.2 4.1 4.5  4.7 ...
</PRE>
OM_MOP_XOR is used internally, but we have not found a plausible use for it in query
contruction, so it will not be mentioned again.
</P>
<P>
A query can therefore be thought of as a process for generating an M set from the terms at
the leaf nodes of the query. Each leaf node gives rise to a posting list of documents with
scores. Each higher level node gives rise to a similar list, and the root node of the tree
contains the final set of documents with scores (or weights), which are candidates for
going into the M set. The M set contains the documents which get the highest weights, and
they are held in the M set in weight order.
</P>
<P>
It is important to realise that within Omsee the structure of a query is optimised for
best performance, and it undergoes various transformations as the query progresses. The
precise way in which the query is built up is therefore of little importance.
</P>

<H3>Using queries</H3>

A plain probabilistic query is created by connecting terms together with OM_MOP_OR
operators. For example,

<PRE>
    OmQuery query();   // undefined query; see next section

    query = OmQuery(OM_MOP_OR, query, OmQuery("regulation"));
    query = OmQuery(OM_MOP_OR, query, OmQuery("import"));
    query = OmQuery(OM_MOP_OR, query, OmQuery("export"));
    query = OmQuery(OM_MOP_OR, query, OmQuery("canned"));
    query = OmQuery(OM_MOP_OR, query, OmQuery("fish"));

</PRE>

This creates a probabilistic query with terms `regulation', `import', `export', `canned'
and `fish'.
<P>
In fact this style of creation is so common that there is the shortcut
construction:

<PRE>
    vector &lt;om_termname&gt; terms;
    terms.push_back("regulation");
    terms.push_back("import");
    terms.push_back("export");
    terms.push_back("canned");
    terms.push_back("fish");

    OmQuery query(OM_MOP_OR, terms.begin(), terms.end());
</PRE>

Suppose now we have this Boolean query,
<PRE>
    ('EEC' - 'France') and ('1989' or '1991' or '1992') and 'Corporate Law'
</PRE>

This could be built up as bquery like this,

<PRE>
    OmQuery bquery1(OM_MOP_AND_NOT, "EEC", "France");

    OmQuery bquery2("1989");
    bquery2 = OmQuery(OM_MOP_OR, bquery2, "1991");
    bquery2 = OmQuery(OM_MOP_OR, bquery2, "1992");

    OmQuery bquery3("Corporate Law");

    OmQuery bquery(OM_MOP_AND, bquery1, OmQuery(OM_MOP_AND(bquery2, bquery3)));
</PRE>

and this can be attached as a filter to <code>query</code> to run the
probabilistic query with a Boolean filter,

<PRE>
    query = OmQuery(OM_MOP_FILTER, query, bquery);
</PRE>

This is the general technique for processing boolean queries, so to run a
pure boolean query, attach it as a filter to an undefined query:

<PRE>
    bquery = OmQuery(OM_MOP_FILTER, OmQuery(), bquery);
    // bquery will now run as a pure boolean
</PRE>

A common requirement in search engine functionality is to run a
probabilistic query where some terms are required to index all the
retrieved documents (`+' terms), and others are required to
index none of the retrieved documents (`-' terms). For example,

<PRE>
    regulation import export +canned +fish -japan
</PRE>

the corresponding query can be set up by,

<PRE>
    vector &lt;om_termname&gt; plus_terms;
    vector &lt;om_termname&gt; minus_terms;
    vector &lt;om_termname&gt; normal_terms;

    plus_terms.push_back("canned");
    plus_terms.push_back("fish");

    minus_terms.push_back("japan");

    normal_terms.push_back("regulation");
    normal_terms.push_back("import");
    normal_terms.push_back("export");

    OmQuery query(OM_MOP_AND_MAYBE,
                  OmQuery(OM_MOP_AND, plus_terms.begin(), plus_terms.end());
                  OmQuery(OM_MOP_OR, normal_terms.begin(), normal_terms.end()));

    query = OmQuery(OM_MOP_AND_NOT,
                    query,
                    OmQuery(OM_MOP_OR, minus_terms.begin(), minus_terms.end()));
</PRE>

<H3>Undefined queries</H3>
<P>
These are an added complication, although they make it possible to write
much neater code, and to perform some extra types of query. (See
<A HREF="#purebool">"Specifying a pure boolean query"</A>).
</P>

<P>
Undefined queries are not empty queries, or queries which match nothing:
rather, they should be thought of as placeholders.  An undefined query is
created by calling the default constructor for OmQuery(), and can then be
used in many places in construction of a query.
</P>

<H3><A NAME="purebool">Specifying a pure boolean query</A></H3>
<P>
Occasionally it may be desirable to perform a purely boolean query, and not
to calculate weights for each document.  This can be performed within Omsee
as follows:
<UL><LI>
Make the desired query, as described above.
For example, putting it in <CODE>query</CODE>:
example:<PRE>
OmQuery query(OM_MOP_AND_NOT, OmQuery("cheese"), OmQuery("bread"));
</PRE>
</LI><LI>
Make a pure boolean query, by filtering a null query with the boolean query.
For example:
<PRE>
OmQuery boolquery(OM_MOP_FILTER, OmQuery(), query);
</PRE>
</LI></UL>

The boolquery will return a set of documents matching the criteria supplied:
each document in the result set will have a weight of 0.
</P>

<H2>Retrieving the results of a query</H2>

<P>
The OmEnquire class does not require that a method be called in order to
perform the query.  Rather, you simply ask for the results of a query,
and it will perform whatever calculations are neccessary to provide the
answer:
</P>
<PRE>
OmMSet <A HREF="apidoc/html/class_OmEnquire.html">OmEnquire::get_mset</A>(om_doccount first,
                           om_doccount maxitems,
                           const OmRSet * omrset = 0,
                           const OmMatchOptions * moptions = 0,
                           const OmMatchDecider * mdecider = 0) const
</PRE>
<P>
When asking for the results, you must specify (in <CODE>first</CODE>) the
first item in the result set to return, where the numbering starts at zero
(so a value of
zero corresponds to the first item returned being that with the highest
score, and a value of 10 corresponds to the first 10 items being ignored,
and the returned items starting at the eleventh).
</P>
<P>
You must also specify (in <CODE>maxitems</CODE>) the the maximum number of
items to return.  Unless there are not enough matching items, precisely
this number of items will be returned.
If <CODE>maxitems</CODE> is zero, no items will be returned, but the usual
statistics (such as the maximum possible weight which a document could be
assigned by the query) will be calculated.  (See &quot;The OmMSet&quot; below).
</P>

<H3>The OmMSet</H3>
<P>
Query results are returned in an
<A HREF="apidoc/html/class_OmMSet.html"><CODE>OmMSet</CODE></A> object.  The prime
field in this is <CODE>items</CODE>, which is a list of
<A HREF="apidoc/html/class_OmMSetItem.html"><CODE>OmMSetItem</CODE></A>'s
comprising the
selected part of the match results.  This list is in descending sorted order
of relevance (so the most relevant document is first in the list).
Each <CODE>OmMSet</CODE> item contains a document id, and the weight
calculated for this document.
</P>
<P>
An <CODE>OmMSet</CODE> also contains various information about the search
result:
<TABLE>
<TR><TD VALIGN="top">
<CODE>firstitem</CODE>
</TD><TD>
The index of the first item in the result which was put into the mset.
(Corresponding to <CODE>first</CODE> in
<CODE>OmEnquire::get_mset()</CODE>)
</TD></TR><TR><TD VALIGN="top">
<CODE>max_attained</CODE>
</TD><TD VALIGN="top">
The greatest weight which is attained in the full results of the search.
</TD></TR><TR><TD VALIGN="top">
<CODE>max_possible</CODE>
</TD><TD VALIGN="top">
The maximum possible weight in the mset.
</TD></TR><TR><TD VALIGN="top">
<CODE>docs_considered</CODE>
</TD><TD VALIGN="top">
The number of documents matching the query considered for the mset.
This provides a lower bound on the number of documents in the database
which have a weight greater than zero.  Note that this value may change
if the search is recalculated with different values for <CODE>first</CODE> or
<CODE>max_items<CODE>.
</TD><TR>
</TABLE>
</P>
<P>
See the <A HREF="apidoc/html/class_OmMSet.html">automatically extracted documentation</A>
for more details of these fields.
</P>
<P>
The <CODE>OmMSet</CODE> also provides methods for converting the score
calculated for a given document into a percentage value, suitable for
displaying to a user.  This may be done using the
<A HREF="apidoc/html/class_OmMSet.html"><CODE>convert_to_percent()</CODE></A>
methods:
<PRE>
     int OmMSet::convert_to_percent(const OmMSetItem &amp; item) const
     int OmMSet::convert_to_percent(om_weight wt) const
</PRE>
These methods return a value in the range 0 to 100, which will be
0 if and only if the item did not match the query at all.
</P>

<H3>Getting the document's data</H3>
<P>
Each document in the database has some data associated with it,
represented by an
<A HREF="apidoc/html/class_OmDocument.html"><CODE>OmDocument</CODE></A> object.
There are some arbitrary numeric keys (which are not yet available,
and mainly useful in the match process) and an arbitrary lump of
data.  To get the <CODE>OmDocument</CODE> object, use
<A HREF="apidoc/html/class_OmEnquire.html"><CODE>OmEnquire::get_doc()</CODE></A>.
The returned <CODE>OmDocument</CODE> is fairly cheap to copy around.
</P> <P>
This data can be used to store a summary of the document along
with a URL, for example, or anything else the application developer
would like.
</P><P>
The data can be retrieved with
<A HREF="apidoc/html/class_OmDocument.html"><CODE>OmDocument::get_data()</CODE></A>
from the <CODE>OmDocument</CODE> object.  This returns an <CODE>OmData</CODE>
object containing a C++ string with the data.  It can include embedded nulls
or other special characters.
</P>

<H2>Specifying a relevance set</H2>
<P>
Omsee supports the idea of relevance feedback: that is, of allowing the user
to mark documents as being relevant to the search, and using this information
to modify the search.  This is supported by means of relevance sets, which
are simply sets of document id's which are marked as relevant.  These
are held in <A HREF="apidoc/html/class_OmRSet.html"><CODE>OmRSet</CODE></A> objects,
one of which may optionally be supplied to Omsee in the
<CODE>omrset</CODE> parameter when calling
<CODE>OmEnquire::get_mset()</CODE>.
</P>

<H3>Match options</H3>

<P>
There are various additional options which may be specified when
performing the query.  These are specified by passing an
<A HREF="apidoc/html/class_OmMatchOptions.html"><CODE>OmMatchOptions</CODE></A>
object.  If no such object is passed, the default options will be
used.  The options are as follows.
</P>
<TABLE>
<TR><TD VALIGN="top">
<B>collapse key</B>
</TD><TD VALIGN="top">
Each document in a database may have a set of numbered keys.   The
contents of each key is a string of arbitrary length.
The <CODE>OmMatchOptions::<A HREF="apidoc/html/class_OmMatchOptions.html">set_collapse_key</A>(om_keyno key_)</CODE>
method specifies a key number upon which to remove duplicates, and the
<CODE>OmMatchOptions::<A HREF="apidoc/html/class_OmMatchOptions.html">set_no_collapse</A>()</CODE>
method specifies that no duplicate removal should be done.
Only one duplicate removal key may be specified at any time, and the
default is to perform no duplicate removal.
</TD></TR><TR><TD VALIGN="top">
<B>percentage cutoff</B>
</TD><TD VALIGN="top">
It may occasionally be desirable to exclude any documents which have a
weight less than a given percentage value.  This may be done using
<CODE>OmMatchOptions::<A HREF="apidoc/html/class_OmMatchOptions.html">set_percentage_cutoff()</A></CODE>.
Note that documents rarely score 100 percent, so using
set_percentage_cutoff(100) will be unlikely to return any documents.
</TD></TR><TR><TD VALIGN="top">
<B>sort direction</B>
</TD><TD VALIGN="top">
Some weighting functions may frequently result in several documents being
returned with the same weight.  In this case, by default, the documents
will be returned in ascending document id order.  This can be changed
by using
<CODE>OmMatchOptions::<A HREF="apidoc/html/class_OmMatchOptions.html">set_sort_forward()</A></CODE>
to set the sort direction.  <CODE>set_sort_forward(false)</CODE> may be
useful, for example, when it would be best to return the newest documents,
and new documents are being added to the end of the database.
</TD></TR>
</TABLE>

<H3>Match decision functors</H3>
<P>
Sometimes it may be useful to return only documents matching criteria
which can't be easily represented by queries.  This can be done using
a match decision functor.  To set such a condition, derive a class
from <CODE>OmMatchDecider</CODE> and override the function operator,
<CODE>operator()(const OmDocument *doc)</CODE>.  The operator can make
a decision based on the document keys via <CODE>OmDocument::get_key(om_keyno)</CODE>.
</p>
<p>
The functor will also have access to the document data stored in the
database (via <CODE>OmDocument::get_data()</CODE>), but beware that, for
most database backends, this is an expensive operation and is likely to slow
down the search considerably.
</P>

<H2>Expand - Suggesting new terms for the query</H2>
<P>
Omsee also supports the idea of calculating terms to add to the
query, based on the relevant documents supplied.  A set of such
terms, together with their weights, may be returned by:
<PRE>
OmESet OmEnquire::<A HREF="apidoc/html/class_OmEnquire.html">get_eset</A>(om_termcount maxitems,
                           const OmRSet &amp; omrset,
                           const OmExpandOptions * eoptions = 0,
                           const OmExpandDecider * edecider = 0) const
</PRE>
</P>
<P>
As for <CODE>get_mset</CODE>, up to <CODE>maxitems</CODE> expand terms
will be returned, with fewer being returned if and only if no more terms
could be found.
</P>
<P>
The expand terms are returned in sorted weight order in an
<A HREF="apidoc/html/class_OmESet.html"><CODE>OmESet</CODE></A> item.
</P>

<H3>Expand options</H3>
<P>
Options to be used when performing the expand may be set using an
<A HREF="apidoc/html/class_OmExpandOptions.html"><CODE>OmExpandOptions</CODE></A>.
</P>
<P>
Currently, there is only one such option:
<PRE>
use_query_terms(bool allow_query_terms_)
</PRE>
If <CODE>allow_query_terms_</CODE> is <CODE>true</CODE>, terms which are
already in the query will be returned by <CODE>get_eset()</CODE>.<BR>
The default is <CODE>false</CODE>.
</P>

<H3>Expand decision functors</H3>
<P>
It is often useful to allow only certain classes of term to be returned
in the expand set.  For example, there may be special terms in the
database with various prefixes, which should be removed from the expand
set.  This is accomplished by providing a decision functor.  To do this,
derive a class from <CODE>OmExpandDecider</CODE> and override the
function operator, <CODE>operator()(const om_termname &amp;)</CODE>.
The functor is called with each term before it is added to the set,
and it may accept (by returning <CODE>true</CODE>) or reject (by returning
<CODE>false</CODE>) the term as appropriate.
</P>

<H2>Query batches</H2>
<P>
In some applications you may want to run many queries against the
same database as a batch.  Omsee provides an API to do this, with the
<CODE>OmBatchEnquire</CODE> class.  This is currently implemented
as a wrapper around OmEnquire.  Using <CODE>OmBatchEnquire</CODE>
will make it possible to take advantage of possible future
optimisations.
</P>

<H3>Setting up the database</H3>
<P>
An <CODE>OmBatchEnquire</CODE>
object is constructed in the same way as an <CODE>OmEnquire</CODE>,
using an <CODE>OmDatabase</CODE> object to specify the database.
</P>

<H3>Setting up the batch query</H3>
<P>
For each query in the batch, you need to provide the query as well as
the arguments that would go to <CODE>OmEnquire::get_mset()</CODE> -
the match options, number of matches to return, etc.  For each query
fill in the fields of an <CODE>OmBatchEnquire::query_desc</CODE>
structure, add it to a container of type <CODE>OmBatchEnquire::query_batch</CODE>,
and pass the container to <CODE>OmBatchEnquire::set_queries(const OmBatchEnquire::query_batch &amp;queries)</CODE>.
</P>

<H3>Running the batch query</H3>
<P>
Once the query batch is set up, you can run the queries by calling
<CODE>OmBatchEnquire::get_msets()</CODE>.  It returns a container
(of type <CODE>OmBatchEnquire::mset_batch</CODE>) of
<CODE>OmBatchEnquire::batch_result</CODE> objects.  The container
will have as many elements as there were queries in the batch,
with the results in the same order.  The <CODE>OmMSet</CODE>s
are not returned directly because some of the results may be invalid,
for example if an invalid argument is supplied for a particular query.
When this happens, <CODE>OmBatchEnquire</CODE> continues to process
the remaining queries unless a more catastrophic error happens, for
example a fatal database error, in which case an exception will be
thrown.
</P><P>
The main operation which can be done on a <CODE>batch_result</CODE> is
to call <CODE>value()</CODE>, which will usually return the <CODE>OmMSet</CODE>
associated with the relevant query.  If that query failed, however,
<CODE>value()</CODE> will throw an exception of type <CODE>OmInvalidResultError</CODE>.  The validity of a result can also be determined by calling
<CODE>is_valid()</CODE> to avoid an exception.
</P>

<H2>Thread safety</H2>
<P>
All of the main Omsee API classes (<CODE>OmEnquire</CODE>,
<CODE>OmQuery</CODE>, <CODE>OmDatabase</CODE>,
<CODE>OmBatchEnquire</CODE>) are protected by
pthread mutexes when available and not disabled.  This means that
the objects will not get into an inconsistent state as a result
of concurrent accesses by different threads.  Note that changing
the query from one thread while retrieving results with another
will still lead to unexpected results which depend on which
thread gets there first.
</P>

<H2>Examples</H2>
<P>
Extensively documented examples of simple usage of the Omsee API for
creating databases and then for searching through them are given in the
<A HREF="quickstart.html">QuickStart</A> tutorial.
</P>
<P>
Further examples of usage of Omsee are available in the om-examples package.
</P>

<!-- FOOTER $Author$ $Date$ $Id$ -->
</BODY>
</HTML>
