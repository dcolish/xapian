#!/usr/bin/python
from omuscat import *
import os
import sys

TestFail = 'TestFail'

def create_dir_if_needed(dirname):
    import os
    import stat
    try:
        sbuf = os.stat(dirname)
	if (not stat.S_ISDIR(sbuf[stat.ST_MODE])):
	    raise IOError, "Not a directory"
	return 0
    except OSError:
        # create the directory
	os.mkdir(dirname)
	return 1

class BackendManager:
    def __init__(self):
        self.datadir = None

    def set_datadir(self, datadir_):
        self.datadir = datadir_

    def get_database(self, dbnames):
        return self.do_getdb(dbnames)

    def do_getdb(self, dbnames):
        return self.do_getdb_sleepy(dbnames)

    def do_getdb_sleepy(self, dbnames):
        parent_dir = ".sleepy"
	create_dir_if_needed(parent_dir)

	dbdir = parent_dir + "/db"
	for dbname in dbnames:
	    dbdir = dbdir + "=" + dbname
	
	if files_exist(self.change_names_to_paths(dbnames)):
	    created = create_dir_if_needed(dbdir)

	    if (created):
	        db = OmWritableDatabase("sleepycat", make_strvec(dbdir))
		if verbose:
		    sys.stderr.write("Indexing to " + dbdir)
		index_files_to_database(db, self.change_names_to_paths(dbnames))
		# let databases be written as database closed...
		db = None
		return OmDatabase("sleepycat", make_strvec(dbdir))
	    else:
	        return OmDatabase("sleepycat", make_strvec(dbdir))
	else:
	    return OmWritableDatabase("sleepycat", make_strvec(dbdir))

    def change_names_to_paths(self, dbnames):
        paths = []
        for dbname in dbnames:
            if len(dbname) > 0:
	        if (self.datadir == None) or (len(self.datadir) == 0):
		    paths.append(dbname)
		else:
		    paths.append(self.datadir + "/" + dbname + ".txt")
	    else:
	        paths.append("")
        return paths

backendmanager = BackendManager()
try:
    srcdir = os.environ['srcdir']
    backendmanager.set_datadir(srcdir + "/../../tests/testdata/")
except:
    print "$srcdir must be set in the environment!"
    raise

def get_database(*dbnames):
    return backendmanager.get_database(dbnames)

def make_dbgrp(*dbs):
    dbgrp = OmDatabaseGroup()

    for db in dbs:
        dbgrp.add_database(db)

    return OmEnquire(dbgrp)

def files_exist(fnames):
    for fname in fnames:
        try:
            os.stat(fname)
	except:
	    return 0
    return 1

def make_strvec(*strs):
    retval = []
    for str in strs:
        retval.append(str)
    
    return retval

def do_get_simple_query_mset(query, maxitems = 10, first = 0):
    enquire = get_simple_database()
    init_simple_enquire(enquire, query)

    return enquire.get_mset(first, maxitems)

def init_simple_enquire(enquire, query = OmQuery("thi")):
    enquire.set_query(query)

def get_simple_database():
    mydb = get_database("apitest_simpledata")
    return make_dbgrp(mydb)

def index_files_to_database(database, paths):
    for path in paths:
        file = open(path, 'r')
	file.seek(0, 2)  # seek to end
	len = file.tell()
	file.seek(0, 0)  # back to beginning
	while file.tell() < len:
	    para = get_paragraph(file)
	    database.add_document(string_to_document(para))
	
	file.close()

def get_paragraph(file):
    para = ""
    linecount = 0
    while 1:
        line = file.readline()
	if (line == ''):
	    break
	
	para = para + line
	linecount = linecount+1
	if (linecount > 30):
	    break
	
	if (linecount >= 3) and (line == '\n'):
	    break
    return para

def string_to_document(paragraph):
    from string import *
    stemmer = OmStem("english")

    document = OmDocumentContents()

    document.set_data(paragraph)

    for i in range(1, 11):
        if (i > len(paragraph)):
	    break
	else:
	    document.add_key(i, paragraph[i])

    position = 1
    while (len(strip(paragraph)) > 0):
        paragraph = strip(paragraph)

	spacepos = 0
	while (spacepos < len(paragraph)) and (paragraph[spacepos] not in whitespace):
	    spacepos = spacepos + 1
	
	word = lower(strip(paragraph[0:spacepos]))
	word = stemmer.stem_word(word)
	if (len(word) > 0):
	    document.add_posting(word, position)
	    position = position + 1
	
	paragraph = paragraph[spacepos:]

    return document

def TEST_AND_EXPLAIN(a, b):
    if (not a):
        print b
        raise TestFail

def TEST_EQUAL(a,b):
    TEST_AND_EXPLAIN(a == b,
      "Expected `" + repr(a) + "' and `" + repr(b) + "' to be equal:" +
      " were " + str(a) + " and " + str(b))

def mset_range_is_same(mset1, first1, mset2, first2, count):
    TEST_AND_EXPLAIN(len(mset1.items) >= first1 + count - 1,
                     "mset1 is too small: expected at least " + str(first1 + count - 1) + " items.\n")

    TEST_AND_EXPLAIN(len(mset2.items) >= first2 + count - 1,
                     "mset2 is too small: expected at least " + str(first2 + count - 1) + " items.\n")

    for i in range(count):
        if (mset1.items[first1+i] != mset2.items[first2+i]):
	    return 0

    return 1

def TEST_EXPECTED_DOCS(mset, *dids):
    expect = dids
    def to_did(item):
        return item[OMMSET_DID]
    got_dids = map(to_did, mset.items)
    if (got_dids != expect):
        if verbose:
            print "Match set had unexpected documents:"
	    print "Got: ", str(got_dids)
	    print "Expected: ", str(expect)

def floats_are_equal_enough(a, b):
    import math
    if math.fabs(a - b) > 1E-5:
         return 0
    return 1

def weights_are_equal_enough(a, b):
    if floats_are_equal_enough(a,b):
        return 1

    if verbose:
        print "Got weight of", a, ", expected weight of", b

    return 0

def mset_range_is_same_weights(mset1, first1, mset2, first2, count):
    TEST_AND_EXPLAIN(len(mset1.items) >= first1 + count - 1,
                     "mset1 is too small: expected at least " +
		     str(first1 + count - 1) + " items.\n")

    TEST_AND_EXPLAIN(len(mset2.items) >= first2 + count - 1,
                     "mset2 is too small: expected at least " +
		     str(first2 + count - 1) + " items.\n")

    for i in range(count):
        if mset1.items[first1+i][OMMSET_WT] != mset2.items[first2+i][OMMSET_WT]:
	    return 0

    return 1
